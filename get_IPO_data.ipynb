{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-07T16:33:34.252545Z",
     "start_time": "2021-02-07T16:33:25.335022Z"
    }
   },
   "outputs": [],
   "source": [
    "# import libraries\n",
    "import requests\n",
    "import time\n",
    "from datetime import datetime\n",
    "import json\n",
    "import sys\n",
    "import pandas as pd\n",
    "pd.set_option('display.max_columns', 500)  #allows display of all columns in dfs\n",
    "\n",
    "import numpy as np\n",
    "from sqlalchemy.ext.automap import automap_base\n",
    "from sqlalchemy.orm import Session\n",
    "from sqlalchemy import create_engine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-01T21:13:26.390647Z",
     "start_time": "2021-02-01T21:13:26.344735Z"
    }
   },
   "outputs": [],
   "source": [
    "# mysql login info\n",
    "sys.path.insert(0, '../../Key')\n",
    "from mysql_secret import dbuser, dbpass, dbhost, dbname\n",
    "engine = create_engine(f'mysql://{dbuser}:{dbpass}@{dbhost}/{dbname}?charset=utf8')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scrape IPOs\n",
    "Retrieve IPO stock information from Nasdaq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-01T21:15:53.338715Z",
     "start_time": "2021-02-01T21:15:53.334693Z"
    }
   },
   "outputs": [],
   "source": [
    "current_year_month = datetime.today().strftime('%Y-%m')\n",
    "current_year_month"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-01T21:15:53.778824Z",
     "start_time": "2021-02-01T21:15:53.672031Z"
    }
   },
   "outputs": [],
   "source": [
    "# scrape nasdaq, Ex: https://api.nasdaq.com/api/ipo/calendar?date=2020-08\n",
    "# note, had to create headers due to time out, solution found here: https://stackoverflow.com/questions/46862719/pythons-requests-library-timing-out-but-getting-the-response-from-the-browser\n",
    "url = f'https://api.nasdaq.com/api/ipo/calendar?date={current_year_month}'\n",
    "headers = {\"User-Agent\":\"Mozilla/5.0 (Macintosh; Intel Mac OS X 10_14_5) AppleWebKit/605.1.15 (KHTML, like Gecko) Version/12.1.1 Safari/605.1.15\",\"Accept-Language\": \"en-gb\",\"Accept-Encoding\":\"br, gzip, deflate\",\"Accept\":\"test/html,application/xhtml+xml,application/xml;q=0.9,*/*;q=0.8\",\"Referer\":\"http://www.google.com/\"}\n",
    "\n",
    "response = requests.get(url, headers=headers)\n",
    "data = response.text\n",
    "data = json.loads(data)\n",
    "print(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-01T21:15:54.588592Z",
     "start_time": "2021-02-01T21:15:54.584601Z"
    }
   },
   "outputs": [],
   "source": [
    "# create list of scraped dataframes to concatenate\n",
    "scraped_ipo_dfs = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-01T21:15:55.281730Z",
     "start_time": "2021-02-01T21:15:55.267769Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# gets priced IPOs for each record on nasdaq (values) = [(expression) for (value) in (collection)]\n",
    "priced_ipos = data[\"data\"][\"priced\"][\"rows\"]\n",
    "\n",
    "# if there are priced IPOs create dataframe\n",
    "if priced_ipos:\n",
    "    \n",
    "    symbols = [priced_ipos[x][\"proposedTickerSymbol\"] for x in range(len(priced_ipos))]\n",
    "    company = [priced_ipos[x][\"companyName\"] for x in range(len(priced_ipos))]\n",
    "    exchange = [priced_ipos[x][\"proposedExchange\"] for x in range(len(priced_ipos))]\n",
    "    proposed_share_price = [priced_ipos[x][\"proposedSharePrice\"] for x in range(len(priced_ipos))]\n",
    "    shares_offered = [priced_ipos[x][\"sharesOffered\"].replace(\",\", '') for x in range(len(priced_ipos))]\n",
    "    priced_date = [priced_ipos[x][\"pricedDate\"] for x in range(len(priced_ipos))]\n",
    "    dollar_val_shares = [priced_ipos[x][\"dollarValueOfSharesOffered\"].replace(\",\", '').replace(\"$\",'') for x in range(len(priced_ipos))]\n",
    "\n",
    "    # dataframe with stock info\n",
    "    nasdaq_priced_df = pd.DataFrame({\"symbol\" : symbols,\n",
    "                                       \"company\" : company,\n",
    "                                       \"exchange\" : exchange, \n",
    "                                       \"proposed_share_price\" : proposed_share_price,\n",
    "                                       \"shares_offered\" : shares_offered,\n",
    "                                       \"priced_date\" : priced_date,\n",
    "                                       \"dollar_val_shares\" : dollar_val_shares,\n",
    "                                       \"deal_status\" : \"priced\"\n",
    "                                       })\n",
    "    scraped_ipo_dfs.append(nasdaq_priced_df)\n",
    "    print(f\"{len(priced_ipos)} priced IPOs\")\n",
    "else:\n",
    "    print(\"no priced IPOs\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-01T21:15:56.323089Z",
     "start_time": "2021-02-01T21:15:56.308131Z"
    }
   },
   "outputs": [],
   "source": [
    "# gets lists for each record on nasdaq (values) = [(expression) for (value) in (collection)]\n",
    "\n",
    "upcoming_ipos = data[\"data\"][\"upcoming\"][\"upcomingTable\"][\"rows\"]\n",
    "\n",
    "if upcoming_ipos:\n",
    "    symbols = [upcoming_ipos[x][\"proposedTickerSymbol\"] for x in range(len(upcoming_ipos))]\n",
    "    company = [upcoming_ipos[x][\"companyName\"] for x in range(len(upcoming_ipos))]\n",
    "    exchange = [upcoming_ipos[x][\"proposedExchange\"] for x in range(len(upcoming_ipos))]\n",
    "    proposed_share_price = [upcoming_ipos[x][\"proposedSharePrice\"] for x in range(len(upcoming_ipos))]\n",
    "    shares_offered = [upcoming_ipos[x][\"sharesOffered\"].replace(\",\", '') for x in range(len(upcoming_ipos))]\n",
    "    priced_date = [upcoming_ipos[x][\"expectedPriceDate\"] for x in range(len(upcoming_ipos))]\n",
    "    dollar_val_shares = [upcoming_ipos[x][\"dollarValueOfSharesOffered\"].replace(\",\", '').replace(\"$\",'') for x in range(len(upcoming_ipos))]\n",
    "\n",
    "    # dataframe with stock info\n",
    "    nasdaq_upcoming_df = pd.DataFrame({\"symbol\" : symbols,\n",
    "                                       \"company\" : company,\n",
    "                                       \"exchange\" : exchange, \n",
    "                                       \"proposed_share_price\" : proposed_share_price,\n",
    "                                       \"shares_offered\" : shares_offered,\n",
    "                                       \"priced_date\" : priced_date,\n",
    "                                       \"dollar_val_shares\" : dollar_val_shares,\n",
    "                                       \"deal_status\" : \"expected\"\n",
    "                                       })\n",
    "    scraped_ipo_dfs.append(nasdaq_upcoming_df)\n",
    "    print(f\"{len(upcoming_ipos)} upcoming IPOs\")\n",
    "else: \n",
    "    print(\"no upcoming IPOs\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-01T21:15:58.339082Z",
     "start_time": "2021-02-01T21:15:58.308139Z"
    }
   },
   "outputs": [],
   "source": [
    "# combine IPO dataframes\n",
    "ipo_df = pd.concat(scraped_ipo_dfs, ignore_index=True, sort=False)\n",
    "\n",
    "# change column datatypes\n",
    "ipo_df[['shares_offered', 'dollar_val_shares']] = ipo_df[['shares_offered', 'dollar_val_shares']].apply(pd.to_numeric)\n",
    "ipo_df['priced_date'] = pd.to_datetime(ipo_df['priced_date'], format=\"%m/%d/%Y\")\n",
    "ipo_df = ipo_df.sort_values(by='deal_status', ascending=False).reset_index(drop=True)\n",
    "ipo_df = ipo_df.drop_duplicates(subset=\"symbol\", keep=\"first\")\n",
    "print(ipo_df.dtypes)\n",
    "ipo_df = ipo_df.dropna()\n",
    "\n",
    "# update symbols with apostrophe.U issue (Ex: \"NBA'U\" as a symbol, they come in this format sometimes in Nasdaq and \n",
    "# in order to pull correctly from yahoo need the apostrophe.U removed\n",
    "ipo_df[\"symbol\"] = ipo_df[\"symbol\"].str.replace(\"'U\",\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# New IPOs to Database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-01T21:16:04.464713Z",
     "start_time": "2021-02-01T21:16:03.854084Z"
    }
   },
   "outputs": [],
   "source": [
    "# Bring in ipo table\n",
    "engine = create_engine(f'mysql://{dbuser}:{dbpass}@{dbhost}/{dbname}?charset=utf8')\n",
    "connection = engine.connect()\n",
    "sql_ipo_df = pd.read_sql(\"SELECT * FROM stocks\", connection)\n",
    "sql_ipo_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-01T21:16:05.759153Z",
     "start_time": "2021-02-01T21:16:05.745158Z"
    }
   },
   "outputs": [],
   "source": [
    "new_ipos_df = ipo_df[~ipo_df[\"symbol\"].isin(sql_ipo_df[\"symbol\"])]\n",
    "new_ipos_df.head()\n",
    "new_ipos_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-01T21:16:20.948870Z",
     "start_time": "2021-02-01T21:16:20.363277Z"
    }
   },
   "outputs": [],
   "source": [
    "# load data\n",
    "engine = create_engine(f'mysql://{dbuser}:{dbpass}@{dbhost}/{dbname}?charset=utf8')\n",
    "new_ipos_df.to_sql('stocks', con=engine, if_exists='append', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Update IPOs in Database\n",
    "Any IPO that is deal status \"expected\" may have new data, so records should be updated to reflect most recent pull"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-01T21:18:27.742469Z",
     "start_time": "2021-02-01T21:18:27.702553Z"
    }
   },
   "outputs": [],
   "source": [
    "# query IPOs with expected status in SQL database\n",
    "sql_expected = sql_ipo_df.query(\"deal_status == 'expected'\")\n",
    "sql_expected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-01T21:18:34.114885Z",
     "start_time": "2021-02-01T21:18:34.102881Z"
    }
   },
   "outputs": [],
   "source": [
    "# expected stocks in SQL database that are in new IPO pull from nasdaq \n",
    "stocks_to_update = ipo_df[ipo_df[\"symbol\"].isin(sql_expected[\"symbol\"])]\n",
    "stocks_to_update"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-02T23:41:30.955036Z",
     "start_time": "2021-01-02T23:41:30.899186Z"
    }
   },
   "outputs": [],
   "source": [
    "# create engine\n",
    "engine = create_engine(f'mysql://{dbuser}:{dbpass}@{dbhost}/{dbname}?charset=utf8')\n",
    "\n",
    "# Declare a Base using `automap_base()`\n",
    "Base = automap_base()\n",
    "\n",
    "# Use the Base class to reflect the database tables\n",
    "Base.prepare(engine, reflect=True)\n",
    "\n",
    "# Print all of the classes mapped to the Base\n",
    "Base.classes.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-02T23:41:31.958003Z",
     "start_time": "2021-01-02T23:41:31.955002Z"
    }
   },
   "outputs": [],
   "source": [
    "# Assign the ipo class to a variable called `IPO`\n",
    "Stocks = Base.classes.stocks\n",
    "\n",
    "# Create a session\n",
    "session = Session(engine)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-02T23:41:32.793116Z",
     "start_time": "2021-01-02T23:41:32.787157Z"
    }
   },
   "outputs": [],
   "source": [
    "# Use the session to query ipo table and display the first 5 symbols\n",
    "for r in session.query(Stocks.symbol, Stocks.company).limit(5).all():\n",
    "    print(r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-02T23:42:03.558122Z",
     "start_time": "2021-01-02T23:42:03.539173Z"
    }
   },
   "outputs": [],
   "source": [
    "for row in stocks_to_update.itertuples():\n",
    "\n",
    "    # Get the record we want to change\n",
    "    stock = session.query(Stocks).filter(Stocks.symbol==row.symbol).first()\n",
    "\n",
    "    # Change the record\n",
    "    stock.proposed_share_price = stocks_to_update.loc[stocks_to_update[\"symbol\"] == row.symbol, 'proposed_share_price'].iloc[0]\n",
    "    stock.shares_offered = stocks_to_update.loc[stocks_to_update[\"symbol\"] == row.symbol, 'shares_offered'].iloc[0]\n",
    "    stock.priced_date = stocks_to_update.loc[stocks_to_update[\"symbol\"] == row.symbol, 'priced_date'].iloc[0]\n",
    "    stock.dollar_val_shares = stocks_to_update.loc[stocks_to_update[\"symbol\"] == row.symbol, 'dollar_val_shares'].iloc[0]\n",
    "    stock.deal_status = stocks_to_update.loc[stocks_to_update[\"symbol\"] == row.symbol, 'deal_status'].iloc[0]\n",
    "\n",
    "# Update the database\n",
    "session.commit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stock Performance\n",
    "To find these URLs go to a stock tickers page on Yahoo finance. When clicking on a tab open inspector > network > XHR > headers.  URL will display. \n",
    "\n",
    "General URL:  \n",
    "https://query1.finance.yahoo.com/v8/finance/chart/AAPL?formatted=true&crumb=T18HKACbWPn&lang=en-US&region=US&events=div%7Csplit&includeAdjustedClose=true&interval=1d&range=2y&corsDomain=finance.yahoo.com\n",
    "\n",
    "URL with Unix Date Selection (period1=xxxxxxx&period2=xxxxxxxxxx):\n",
    "https://query2.finance.yahoo.com/v8/finance/chart/AAPL?formatted=true&crumb=T18HKACbWPn&lang=en-US&region=US&includeAdjustedClose=true&interval=1d&period1=1546300800&period2=1608076800&events=div%7Csplit&corsDomain=finance.yahoo.com"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-07T16:37:20.645325Z",
     "start_time": "2021-02-07T16:37:20.636346Z"
    }
   },
   "outputs": [],
   "source": [
    "# get unix time range for web request\n",
    "start_unixtime = 1514903400  #Jan 2, 2018\n",
    "\n",
    "current_date = datetime.now()\n",
    "print(current_date)\n",
    "\n",
    "current_time = current_date.time()\n",
    "\n",
    "# if its past 5p CST and markets are closed get unix to pull todays info, else pull market data from yesterday\n",
    "if current_time.hour > 16:\n",
    "    earliest_date_time = current_date.replace(hour=17, minute=0, second=0, microsecond=0)\n",
    "else:\n",
    "    earliest_date_time = current_date.replace(hour=0, minute=0, second=0, microsecond=0)\n",
    "print(earliest_date_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# change earliest data time to unix timestamp\n",
    "end_unixtime = time.mktime(earliest_date_time.timetuple())\n",
    "end_unixtime = int(end_unixtime)\n",
    "end_unixtime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-26T01:44:56.379311Z",
     "start_time": "2021-01-26T01:44:56.374329Z"
    }
   },
   "outputs": [],
   "source": [
    "today = datetime.today().strftime(\"%Y-%m-%d\")\n",
    "print(today)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-26T01:51:01.302249Z",
     "start_time": "2021-01-26T01:51:01.176879Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# query stocks from SQL\n",
    "connection = engine.connect()\n",
    "ipo_stocks = pd.read_sql(f\"SELECT symbol, deal_status FROM stocks\", connection)\n",
    "ipo_stocks[\"default_start_unixtime\"] = start_unixtime\n",
    "ipo_stocks[\"end_unixtime\"] = end_unixtime\n",
    "ipo_stocks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-26T01:51:02.858116Z",
     "start_time": "2021-01-26T01:51:02.430991Z"
    }
   },
   "outputs": [],
   "source": [
    "stock_perf_start_unix = pd.read_sql(\"SELECT symbol, max(unix_time) AS max_unix_captured  FROM performance  GROUP BY symbol\"\"\", connection)\n",
    "ipo_stocks = ipo_stocks.merge(stock_perf_start_unix, on=\"symbol\", how=\"outer\")\n",
    "ipo_stocks[\"max_unix_captured\"] = ipo_stocks[\"max_unix_captured\"].fillna(0).astype('int64')\n",
    "ipo_stocks[\"max_unix_captured\"] = ipo_stocks[\"max_unix_captured\"] + 86400  #add a day to latest date captured\n",
    "ipo_stocks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-26T01:51:23.764878Z",
     "start_time": "2021-01-26T01:51:23.747924Z"
    }
   },
   "outputs": [],
   "source": [
    "ipo_stocks[\"start_unixtime\"] = ipo_stocks[[\"default_start_unixtime\", \"max_unix_captured\"]].max(axis=1).astype('int64') \n",
    "ipo_stocks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-26T02:01:44.913822Z",
     "start_time": "2021-01-26T01:51:29.235022Z"
    }
   },
   "outputs": [],
   "source": [
    "# empty list of dfs\n",
    "performance_df_list= []\n",
    "\n",
    "# make requests for performance information for each row\n",
    "for row in ipo_stocks.itertuples():\n",
    "\n",
    "    url = f'https://query2.finance.yahoo.com/v8/finance/chart/{row.symbol}?formatted=true&crumb=T18HKACbWPn&lang=en-US&region=US&includeAdjustedClose=true&interval=1d&period1={row.start_unixtime}&period2={row.end_unixtime}&events=div%7Csplit&corsDomain=finance.yahoo.com'\n",
    "    r = requests.get(url)\n",
    "    print(f\"trying url: {url}\")\n",
    "    if r.ok:\n",
    "        try: \n",
    "            data = r.json()\n",
    "\n",
    "            # get data\n",
    "            timestamp = data[\"chart\"][\"result\"][0][\"timestamp\"]\n",
    "            stk_open = data[\"chart\"][\"result\"][0][\"indicators\"][\"quote\"][0][\"open\"]\n",
    "            stk_close = data[\"chart\"][\"result\"][0][\"indicators\"][\"quote\"][0][\"close\"]\n",
    "            stk_high = data[\"chart\"][\"result\"][0][\"indicators\"][\"quote\"][0][\"high\"]\n",
    "            stk_low = data[\"chart\"][\"result\"][0][\"indicators\"][\"quote\"][0][\"low\"]\n",
    "            stk_vol = data[\"chart\"][\"result\"][0][\"indicators\"][\"quote\"][0][\"volume\"]\n",
    "\n",
    "            #transform into dataframe\n",
    "            df = pd.DataFrame({\"symbol\" : row.symbol,\n",
    "                               \"unix_time\" : timestamp,\n",
    "                               \"date\" : [datetime.fromtimestamp(ts).strftime('%Y-%m-%d') for ts in timestamp],\n",
    "                               \"open\" : stk_open, \n",
    "                               \"close\" : stk_close,\n",
    "                               \"high\" : stk_high,\n",
    "                               \"low\" : stk_low,\n",
    "                               \"volume\" : stk_vol\n",
    "                              })\n",
    "\n",
    "            df['date'] = pd.to_datetime(df['date'], format=\"%Y-%m-%d\")\n",
    "            df['date_pulled'] = today\n",
    "\n",
    "            print(f\"{row.symbol} has results\")\n",
    "            performance_df_list.append(df)\n",
    "        except KeyError:\n",
    "            continue\n",
    "    \n",
    "    else:\n",
    "        print(f\"{row.symbol} NO RESULTS\")\n",
    "\n",
    "    time.sleep(.5)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-22T23:30:31.081783Z",
     "start_time": "2021-01-22T23:30:30.582990Z"
    }
   },
   "outputs": [],
   "source": [
    "# creat one performance df from list of dfs\n",
    "performance_df = pd.concat(performance_df_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# first cleaning step:  remove unix time not divisible by 100 as all desired data appears to have unix divisable by 100\n",
    "performance_df = performance_df.loc[test_df[\"unix_time\"] % 100 == 0]\n",
    "\n",
    "# second clearning step:  remove remaining DUPES\n",
    "performance_df = performance_df.drop_duplicates(subset=['symbol', 'date'], keep='first')\n",
    "\n",
    "performance_df.head(8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-22T03:18:24.699470Z",
     "start_time": "2021-01-22T03:08:28.763Z"
    }
   },
   "outputs": [],
   "source": [
    "# add performance to database\n",
    "# connection = engine.connect()\n",
    "# performance_df.to_sql('performance', con=engine, if_exists='append', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-19T23:39:27.379183Z",
     "start_time": "2020-12-19T23:39:27.166551Z"
    }
   },
   "outputs": [],
   "source": [
    "# pull for one stock example\n",
    "# r = requests.get(f'https://query2.finance.yahoo.com/v8/finance/chart/DFH?formatted=true&crumb=T18HKACbWPn&lang=en-US&region=US&includeAdjustedClose=true&interval=1d&period1=1514903400&period2=1608357600&events=div%7Csplit&corsDomain=finance.yahoo.com')\n",
    "# data = r.json()\n",
    "# print(r)\n",
    "\n",
    "# timestamp = data[\"chart\"][\"result\"][0][\"timestamp\"]\n",
    "# stk_open = data[\"chart\"][\"result\"][0][\"indicators\"][\"quote\"][0][\"open\"]\n",
    "# stk_close = data[\"chart\"][\"result\"][0][\"indicators\"][\"quote\"][0][\"close\"]\n",
    "# stk_high = data[\"chart\"][\"result\"][0][\"indicators\"][\"quote\"][0][\"high\"]\n",
    "# stk_low = data[\"chart\"][\"result\"][0][\"indicators\"][\"quote\"][0][\"low\"]\n",
    "# stk_vol = data[\"chart\"][\"result\"][0][\"indicators\"][\"quote\"][0][\"volume\"]\n",
    "\n",
    "# # dataframe with new stock info\n",
    "# df = pd.DataFrame({\"symbol\" : \"RSVAU\",\n",
    "#                    \"unix_time\" : timestamp,\n",
    "#                    \"date\" : [datetime.fromtimestamp(ts).strftime('%Y-%m-%d') for ts in timestamp],\n",
    "#                    \"open\" : stk_open, \n",
    "#                    \"close\" : stk_close,\n",
    "#                    \"high\" : stk_high,\n",
    "#                    \"low\" : stk_low,\n",
    "#                    \"volume\" : stk_vol\n",
    "#                   })\n",
    "\n",
    "# df['date'] = pd.to_datetime(df['date'], format=\"%Y-%m-%d\")\n",
    "# df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Industry Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-13T18:33:38.372487Z",
     "start_time": "2021-01-13T18:33:38.303782Z"
    }
   },
   "outputs": [],
   "source": [
    "# get unix time range for web request\n",
    "start_unixtime = 1514903400  #Jan 2, 2018\n",
    "\n",
    "current_date = datetime.now()\n",
    "print(current_date)\n",
    "\n",
    "earliest_date_time = current_date.replace(hour=0, minute=0, second=0, microsecond=0)\n",
    "print(earliest_date_time)\n",
    "\n",
    "end_unixtime = time.mktime(earliest_date_time.timetuple())\n",
    "end_unixtime = int(end_unixtime)\n",
    "end_unixtime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-13T18:33:38.713191Z",
     "start_time": "2021-01-13T18:33:38.709227Z"
    }
   },
   "outputs": [],
   "source": [
    "today = datetime.today().strftime(\"%Y-%m-%d\")\n",
    "print(today)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-13T18:33:39.423068Z",
     "start_time": "2021-01-13T18:33:39.416059Z"
    }
   },
   "outputs": [],
   "source": [
    "# industry index's list for requests\n",
    "ind_idx_lookup_list = ['%5EDJI', '%5EIXIC', '%5EGSPC']\n",
    "ind_idx_symbol_list = ['DJI', 'IXIC', 'GSPC']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-13T18:33:43.729241Z",
     "start_time": "2021-01-13T18:33:43.701352Z"
    }
   },
   "outputs": [],
   "source": [
    "# initial industry dataframe to interate through for requests\n",
    "ind_df = pd.DataFrame({'symbol_lookup': ind_idx_lookup_list,\n",
    "                      'symbol': ind_idx_symbol_list})\n",
    "ind_df[\"default_start_unixtime\"] = start_unixtime\n",
    "ind_df[\"end_unixtime\"] = end_unixtime\n",
    "ind_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-13T18:33:44.833381Z",
     "start_time": "2021-01-13T18:33:44.731564Z"
    }
   },
   "outputs": [],
   "source": [
    "# update to only pull new date information\n",
    "ind_perf_start_unix = pd.read_sql(\"SELECT symbol, max(unix_time) AS max_unix_captured  FROM industry_performance  GROUP BY symbol\"\"\", connection)\n",
    "ind_df = ind_df.merge(ind_perf_start_unix, on=\"symbol\", how=\"outer\")\n",
    "ind_df[\"max_unix_captured\"] = ind_df[\"max_unix_captured\"].fillna(0).astype('int64')\n",
    "ind_df[\"max_unix_captured\"] = ind_df[\"max_unix_captured\"] + 86400  #add a day to latest date captured\n",
    "ind_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-13T18:34:21.430216Z",
     "start_time": "2021-01-13T18:34:21.413262Z"
    }
   },
   "outputs": [],
   "source": [
    "ind_df[\"start_unixtime\"] = ind_df[[\"default_start_unixtime\", \"max_unix_captured\"]].max(axis=1).astype('int64') \n",
    "ind_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-10T15:50:53.316198Z",
     "start_time": "2021-01-10T15:50:50.796210Z"
    }
   },
   "outputs": [],
   "source": [
    "# empty list of dfs\n",
    "performance_df_list= []\n",
    "\n",
    "# make requests for performance information for each row\n",
    "for row in ind_df.itertuples():\n",
    "\n",
    "    url = f'https://query2.finance.yahoo.com/v8/finance/chart/{row.symbol_lookup}?formatted=true&crumb=T18HKACbWPn&lang=en-US&region=US&includeAdjustedClose=true&interval=1d&period1={row.start_unixtime}&period2={row.end_unixtime}&events=div%7Csplit&corsDomain=finance.yahoo.com'\n",
    "    r = requests.get(url)\n",
    "    print(f\"trying url: {url}\")\n",
    "    if r.ok:\n",
    "        try: \n",
    "            data = r.json()\n",
    "\n",
    "            # get data\n",
    "            timestamp = data[\"chart\"][\"result\"][0][\"timestamp\"]\n",
    "            stk_open = data[\"chart\"][\"result\"][0][\"indicators\"][\"quote\"][0][\"open\"]\n",
    "            stk_close = data[\"chart\"][\"result\"][0][\"indicators\"][\"quote\"][0][\"close\"]\n",
    "            stk_high = data[\"chart\"][\"result\"][0][\"indicators\"][\"quote\"][0][\"high\"]\n",
    "            stk_low = data[\"chart\"][\"result\"][0][\"indicators\"][\"quote\"][0][\"low\"]\n",
    "            stk_vol = data[\"chart\"][\"result\"][0][\"indicators\"][\"quote\"][0][\"volume\"]\n",
    "\n",
    "            #transform into dataframe\n",
    "            df = pd.DataFrame({\"symbol\" : row.symbol,\n",
    "                               \"unix_time\" : timestamp,\n",
    "                               \"date\" : [datetime.fromtimestamp(ts).strftime('%Y-%m-%d') for ts in timestamp],\n",
    "                               \"open\" : stk_open, \n",
    "                               \"close\" : stk_close,\n",
    "                               \"high\" : stk_high,\n",
    "                               \"low\" : stk_low,\n",
    "                               \"volume\" : stk_vol\n",
    "                              })\n",
    "\n",
    "            df['date'] = pd.to_datetime(df['date'], format=\"%Y-%m-%d\")\n",
    "            df['date_pulled'] = today\n",
    "\n",
    "            print(f\"{row.symbol} has results\")\n",
    "            performance_df_list.append(df)\n",
    "        except KeyError:\n",
    "            continue\n",
    "    \n",
    "    else:\n",
    "        print(f\"{row.symbol} NO RESULTS\")\n",
    "\n",
    "    time.sleep(.5)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-10T15:50:56.704718Z",
     "start_time": "2021-01-10T15:50:56.681780Z"
    }
   },
   "outputs": [],
   "source": [
    "ind_performance_df = pd.concat(performance_df_list)\n",
    "ind_performance_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-10T15:51:04.869107Z",
     "start_time": "2021-01-10T15:51:04.649686Z"
    }
   },
   "outputs": [],
   "source": [
    "# add performance to database\n",
    "connection = engine.connect()\n",
    "ind_performance_df.to_sql('industry_performance', con=engine, if_exists='append', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Company Characteristics\n",
    "This will provide city, industry, etc.  \n",
    "https://query1.finance.yahoo.com/v10/finance/quoteSummary/AAPL?modules=assetProfile%2CearningsHistory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-09T15:09:50.707850Z",
     "start_time": "2021-01-09T15:09:50.635083Z"
    }
   },
   "outputs": [],
   "source": [
    "# get symbols from SQL\n",
    "connection = engine.connect()\n",
    "symbols_df = pd.read_sql(\"SELECT symbol FROM stocks\", connection)\n",
    "symbols_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-09T15:09:55.278466Z",
     "start_time": "2021-01-09T15:09:55.260514Z"
    }
   },
   "outputs": [],
   "source": [
    "# get symbols that already have company info\n",
    "symb_in_compinfo = pd.read_sql(\"SELECT symbol FROM company_info\", connection)\n",
    "symb_in_compinfo.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-09T15:10:37.119122Z",
     "start_time": "2021-01-09T15:10:37.106184Z"
    }
   },
   "outputs": [],
   "source": [
    "# remove any symbols company info already avaialable for, only keeping \"new\" symbols\n",
    "symbols_df = symbols_df[~symbols_df[\"symbol\"].isin(symb_in_compinfo[\"symbol\"])]\n",
    "symbols_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-09T15:13:07.473580Z",
     "start_time": "2021-01-09T15:11:35.568623Z"
    }
   },
   "outputs": [],
   "source": [
    "#get characteristics dataframe\n",
    "today = datetime.today().strftime(\"%Y-%m-%d\")\n",
    "\n",
    "# empty list for df\n",
    "symbol = []\n",
    "address = []\n",
    "city = []\n",
    "state = []\n",
    "zip_code = []\n",
    "country = []\n",
    "website = []\n",
    "industry = []\n",
    "sector = []\n",
    "business_summary = []\n",
    "\n",
    "# make requests for characteristic information for each row\n",
    "for row in symbols_df.itertuples():\n",
    "\n",
    "    url = f'https://query1.finance.yahoo.com/v10/finance/quoteSummary/{row.symbol}?modules=assetProfile%2CearningsHistory'\n",
    "    r = requests.get(url)\n",
    "    print(f\"trying url: {url}\")\n",
    "    if r.ok:\n",
    "        try: \n",
    "            data = r.json()\n",
    "            char_dict = data[\"quoteSummary\"][\"result\"][0][\"assetProfile\"]\n",
    "\n",
    "            symbol.append(row.symbol)\n",
    "            address.append(char_dict.get(\"address1\", \"\"))\n",
    "            city.append(char_dict.get(\"city\", \"\"))\n",
    "            state.append(char_dict.get(\"state\", \"\"))  \n",
    "            zip_code.append(char_dict.get(\"zip\", \"\"))  \n",
    "            country.append(char_dict.get(\"country\", \"\"))  \n",
    "            website.append(char_dict.get(\"website\", \"\"))\n",
    "            industry.append(char_dict.get(\"industry\", \"\"))  \n",
    "            sector.append(char_dict.get(\"sector\", \"\"))  \n",
    "            \n",
    "            # shorten the character length of the full business summary\n",
    "            bus_summary = char_dict.get(\"longBusinessSummary\", \"\")\n",
    "            if len(bus_summary) > 252:\n",
    "                bus_summary = bus_summary[:995] + '...'\n",
    "            business_summary.append(bus_summary)\n",
    "                \n",
    "\n",
    "        except KeyError:\n",
    "            continue\n",
    "    \n",
    "    else:\n",
    "        print(f\"{row.symbol} NO RESULTS\")\n",
    "\n",
    "    time.sleep(.25)\n",
    "\n",
    "#transform into dataframe\n",
    "comp_info_df = pd.DataFrame({\"symbol\": symbol,\n",
    "                   \"address\": address,\n",
    "                   \"city\": city,\n",
    "                   \"state\": state,\n",
    "                   \"zip_code\": zip_code,\n",
    "                   \"country\": country,\n",
    "                   \"website\": website,\n",
    "                   \"industry\": industry,\n",
    "                   \"sector\": sector,\n",
    "                   \"business_summary\": business_summary})\n",
    "comp_info_df['date_pulled'] = today\n",
    "comp_info_df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-09T15:13:13.074594Z",
     "start_time": "2021-01-09T15:13:13.034701Z"
    }
   },
   "outputs": [],
   "source": [
    "# add company info to database\n",
    "connection = engine.connect()\n",
    "comp_info_df.to_sql('company_info', con=engine, if_exists='append', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-20T21:45:00.294773Z",
     "start_time": "2020-12-20T21:45:00.154453Z"
    }
   },
   "outputs": [],
   "source": [
    "# get single characteristics for testing\n",
    "# symbol = \"VTAQU\"\n",
    "# url = f'https://query1.finance.yahoo.com/v10/finance/quoteSummary/{symbol}?modules=assetProfile%2CearningsHistory'\n",
    "# r = requests.get(url)\n",
    "# data = r.json()\n",
    "# char_dict = data[\"quoteSummary\"][\"result\"][0][\"assetProfile\"]\n",
    "\n",
    "# address = char_dict.get(\"address1\", \"\")\n",
    "# city = char_dict.get(\"city\", \"\")\n",
    "# state = char_dict.get(\"state\", \"\")  \n",
    "# zip_code = char_dict.get(\"zip\", \"\")  \n",
    "# country = char_dict.get(\"country\", \"\")  \n",
    "# website = char_dict.get(\"website\", \"\")\n",
    "# industry = char_dict.get(\"industry\", \"\")  \n",
    "# sector = char_dict.get(\"sector\", \"\")  \n",
    "# business_summary = char_dict.get(\"longBusinessSummary\", \"\")  \n",
    "\n",
    "# characteristics_df = pd.DataFrame({\"symbol\": symbol,\n",
    "#                                    \"address\": address,\n",
    "#                                    \"city\": city,\n",
    "#                                    \"state\": state,\n",
    "#                                    \"zip_code\": zip_code,\n",
    "#                                    \"country\": country,\n",
    "#                                    \"website\": website,\n",
    "#                                    \"industry\": industry,\n",
    "#                                    \"sector\": sector,\n",
    "#                                    \"business_summary\": business_summary\n",
    "#                                   }\n",
    "#                                   ,index=[0]\n",
    "#                                   )\n",
    "# characteristics_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Update Company Characteristics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-21T23:32:53.705238Z",
     "start_time": "2021-01-21T23:32:53.136156Z"
    }
   },
   "outputs": [],
   "source": [
    "# query characteristics with NULL or blank values for industry or sector\n",
    "engine = create_engine(f'mysql://{dbuser}:{dbpass}@{dbhost}/{dbname}?charset=utf8')\n",
    "connection = engine.connect()\n",
    "ci_limited_df = pd.read_sql(\"\"\"\n",
    "                        SELECT *\n",
    "                        FROM company_info\n",
    "                        WHERE industry IS NULL \n",
    "                            OR industry = ''\n",
    "                            OR sector IS NULL\n",
    "                            OR sector = ''\"\"\", connection)\n",
    "connection.close()\n",
    "ci_limited_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-21T22:41:56.376622Z",
     "start_time": "2021-01-21T22:41:55.652374Z"
    }
   },
   "outputs": [],
   "source": [
    "# create engine\n",
    "engine = create_engine(f'mysql://{dbuser}:{dbpass}@{dbhost}/{dbname}?charset=utf8')\n",
    "\n",
    "# Declare a Base using `automap_base()`\n",
    "Base = automap_base()\n",
    "\n",
    "# Use the Base class to reflect the database tables\n",
    "Base.prepare(engine, reflect=True)\n",
    "\n",
    "# Print all of the classes mapped to the Base\n",
    "Base.classes.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-21T22:42:19.321638Z",
     "start_time": "2021-01-21T22:42:19.317653Z"
    }
   },
   "outputs": [],
   "source": [
    "# Assign the company_info class to a variable called `Company_Info`\n",
    "Comp_Info = Base.classes.company_info\n",
    "\n",
    "# Create a session\n",
    "session = Session(engine)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-21T22:42:37.534764Z",
     "start_time": "2021-01-21T22:42:37.500858Z"
    }
   },
   "outputs": [],
   "source": [
    "# Use the session to query company info table and display the first 5 symbols\n",
    "for r in session.query(Comp_Info.symbol, Comp_Info.address).limit(5).all():\n",
    "    print(r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-21T23:33:31.658762Z",
     "start_time": "2021-01-21T23:33:13.065385Z"
    }
   },
   "outputs": [],
   "source": [
    "#get characteristics dataframe\n",
    "today = datetime.today().strftime(\"%Y-%m-%d\")\n",
    "\n",
    "# empty list for df\n",
    "symbol = []\n",
    "address = []\n",
    "city = []\n",
    "state = []\n",
    "zip_code = []\n",
    "country = []\n",
    "website = []\n",
    "industry = []\n",
    "sector = []\n",
    "business_summary = []\n",
    "\n",
    "# make requests for characteristic information for each row\n",
    "for row in ci_limited_df.itertuples():\n",
    "\n",
    "    url = f'https://query1.finance.yahoo.com/v10/finance/quoteSummary/{row.symbol}?modules=assetProfile%2CearningsHistory'\n",
    "    r = requests.get(url)\n",
    "    print(f\"trying url: {url}\")\n",
    "    if r.ok:\n",
    "        try: \n",
    "            data = r.json()\n",
    "            char_dict = data[\"quoteSummary\"][\"result\"][0][\"assetProfile\"]\n",
    "\n",
    "            symbol.append(row.symbol)\n",
    "            address.append(char_dict.get(\"address1\", \"\"))\n",
    "            city.append(char_dict.get(\"city\", \"\"))\n",
    "            state.append(char_dict.get(\"state\", \"\"))  \n",
    "            zip_code.append(char_dict.get(\"zip\", \"\"))  \n",
    "            country.append(char_dict.get(\"country\", \"\"))  \n",
    "            website.append(char_dict.get(\"website\", \"\"))\n",
    "            industry.append(char_dict.get(\"industry\", \"\"))  \n",
    "            sector.append(char_dict.get(\"sector\", \"\"))  \n",
    "            \n",
    "            # shorten the character length of the full business summary\n",
    "            bus_summary = char_dict.get(\"longBusinessSummary\", \"\")\n",
    "            if len(bus_summary) > 252:\n",
    "                bus_summary = bus_summary[:995] + '...'\n",
    "            business_summary.append(bus_summary)\n",
    "                \n",
    "\n",
    "        except KeyError:\n",
    "            continue\n",
    "    \n",
    "    else:\n",
    "        print(f\"{row.symbol} NO RESULTS\")\n",
    "\n",
    "    time.sleep(.25)\n",
    "\n",
    "#transform into dataframe\n",
    "comp_info_df = pd.DataFrame({\"symbol\": symbol,\n",
    "                   \"address\": address,\n",
    "                   \"city\": city,\n",
    "                   \"state\": state,\n",
    "                   \"zip_code\": zip_code,\n",
    "                   \"country\": country,\n",
    "                   \"website\": website,\n",
    "                   \"industry\": industry,\n",
    "                   \"sector\": sector,\n",
    "                   \"business_summary\": business_summary})\n",
    "comp_info_df['date_pulled'] = today\n",
    "comp_info_df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-22T01:57:04.086465Z",
     "start_time": "2021-01-22T01:57:04.069525Z"
    }
   },
   "outputs": [],
   "source": [
    "# get dataframe for company info that has industry or sector and previously didn't\n",
    "df = comp_info_df.loc[(comp_info_df['industry'] != '')  | (comp_info_df['sector'] != '')]\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-22T02:00:20.416671Z",
     "start_time": "2021-01-22T02:00:19.760814Z"
    }
   },
   "outputs": [],
   "source": [
    "for row in df.itertuples():\n",
    "\n",
    "    # Get the record we want to change\n",
    "    stock = session.query(Comp_Info).filter(Comp_Info.symbol==row.symbol).first()\n",
    "\n",
    "    # Change the record\n",
    "    stock.address = df.loc[df[\"symbol\"] == row.symbol, 'address'].iloc[0]\n",
    "    stock.city = df.loc[df[\"symbol\"] == row.symbol, 'city'].iloc[0]\n",
    "    stock.state = df.loc[df[\"symbol\"] == row.symbol, 'state'].iloc[0]\n",
    "    stock.zip_code = df.loc[df[\"symbol\"] == row.symbol, 'zip_code'].iloc[0]\n",
    "    stock.country = df.loc[df[\"symbol\"] == row.symbol, 'country'].iloc[0]\n",
    "    stock.industry = df.loc[df[\"symbol\"] == row.symbol, 'industry'].iloc[0]\n",
    "    stock.sector = df.loc[df[\"symbol\"] == row.symbol, 'sector'].iloc[0]\n",
    "    stock.business_summary = df.loc[df[\"symbol\"] == row.symbol, 'business_summary'].iloc[0]\n",
    "    stock.date_pulled = df.loc[df[\"symbol\"] == row.symbol, 'date_pulled'].iloc[0]\n",
    "\n",
    "# Update the database\n",
    "session.commit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Market Cap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-13T16:07:25.077155Z",
     "start_time": "2021-01-13T16:07:25.070176Z"
    }
   },
   "outputs": [],
   "source": [
    "# get unix time range for web request\n",
    "start_unixtime = 1514903400  #Jan 2, 2018\n",
    "\n",
    "current_date = datetime.now()\n",
    "print(current_date)\n",
    "\n",
    "earliest_date_time = current_date.replace(hour=0, minute=0, second=0, microsecond=0)\n",
    "print(earliest_date_time)\n",
    "\n",
    "end_unixtime = time.mktime(earliest_date_time.timetuple())\n",
    "end_unixtime = int(end_unixtime)\n",
    "end_unixtime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-13T16:07:26.092978Z",
     "start_time": "2021-01-13T16:07:26.069043Z"
    }
   },
   "outputs": [],
   "source": [
    "# query stocks from SQL\n",
    "connection = engine.connect()\n",
    "ipo_stocks = pd.read_sql(\"SELECT symbol, deal_status FROM stocks WHERE deal_status = 'priced'\", connection)\n",
    "ipo_stocks[\"default_start_unixtime\"] = start_unixtime\n",
    "ipo_stocks[\"end_unixtime\"] = end_unixtime\n",
    "ipo_stocks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-13T16:07:27.064992Z",
     "start_time": "2021-01-13T16:07:27.011145Z"
    }
   },
   "outputs": [],
   "source": [
    "# update to unix to avoid capturing duplicate records\n",
    "comp_fin_start_unix = pd.read_sql(\"SELECT symbol, max(unix_timestamp) AS max_unix_captured  FROM market_cap  GROUP BY symbol\"\"\", connection)\n",
    "ipo_stocks = ipo_stocks.merge(comp_fin_start_unix, on=\"symbol\", how=\"outer\")\n",
    "ipo_stocks[\"max_unix_captured\"] = ipo_stocks[\"max_unix_captured\"].fillna(0).astype('int64')\n",
    "ipo_stocks[\"max_unix_captured\"] = ipo_stocks[\"max_unix_captured\"] + 604800  #add a week to latest date captured\n",
    "ipo_stocks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-13T16:07:31.671294Z",
     "start_time": "2021-01-13T16:07:31.643368Z"
    }
   },
   "outputs": [],
   "source": [
    "ipo_stocks[\"start_unixtime\"] = ipo_stocks[[\"default_start_unixtime\", \"max_unix_captured\"]].max(axis=1).astype('int64') \n",
    "ipo_stocks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-13T16:07:34.596255Z",
     "start_time": "2021-01-13T16:07:34.591269Z"
    }
   },
   "outputs": [],
   "source": [
    "def fn_get_fin_metric_index(df, metric):\n",
    "    \"\"\"returns the index for a given metric is in the list of metrics on yahoo (cannot use a key as it is not a dictionary).\n",
    "    For example, the metric parameteter may be 'trailingMarketCap'. Other options include:\n",
    "    \n",
    "    trailingMarketCap, trailingForwardPeRatio, trailingPeRatio, trailingEnterpriseValue, trailingPegRatio, \n",
    "    trailingEnterprisesValueRevenueRatio, trailingEnterprisesValueEBITDARatio, trailingPsRatio, trailingPbRatio\n",
    "    \"\"\"\n",
    "    idx = df[df[\"metric\"] == metric].index\n",
    "    idx = idx[0]\n",
    "    return idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-13T16:07:34.986285Z",
     "start_time": "2021-01-13T16:07:34.983294Z"
    }
   },
   "outputs": [],
   "source": [
    "# rolling 12 fields are trailingMarketCap, trailingForwardPeRatio, trailingPeRatio, trailingEnterpriseValue, trailingPegRatio, \n",
    "# trailingEnterprisesValueRevenueRatio, trailingEnterprisesValueEBITDARatio, trailingPsRatio, trailingPbRatio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-13T16:14:08.177194Z",
     "start_time": "2021-01-13T16:07:35.745745Z"
    }
   },
   "outputs": [],
   "source": [
    "#get market cap dataframe\n",
    "today = datetime.today().strftime(\"%Y-%m-%d\")\n",
    "\n",
    "# empty list for df\n",
    "symbol_list = []\n",
    "unix_timestamp_list = []\n",
    "date_list = []\n",
    "market_cap_list = []\n",
    "market_cap_fmt_list = []\n",
    "\n",
    "# make requests for characteristic information for each row\n",
    "for row in ipo_stocks.itertuples():\n",
    "\n",
    "    #NOTE NOTE NOTE: WILL NEED UP UPDATE START UNIXTIME AFTER INITIAL RUN\n",
    "    url = f'https://query1.finance.yahoo.com/ws/fundamentals-timeseries/v1/finance/timeseries/{row.symbol}?lang=en-US&region=US&symbol={row.symbol}&padTimeSeries=true&type=quarterlyMarketCap%2CtrailingMarketCap%2CquarterlyEnterpriseValue%2CtrailingEnterpriseValue%2CquarterlyPeRatio%2CtrailingPeRatio%2CquarterlyForwardPeRatio%2CtrailingForwardPeRatio%2CquarterlyPegRatio%2CtrailingPegRatio%2CquarterlyPsRatio%2CtrailingPsRatio%2CquarterlyPbRatio%2CtrailingPbRatio%2CquarterlyEnterprisesValueRevenueRatio%2CtrailingEnterprisesValueRevenueRatio%2CquarterlyEnterprisesValueEBITDARatio%2CtrailingEnterprisesValueEBITDARatio&merge=false&period1={row.start_unixtime}&period2={row.end_unixtime}&corsDomain=finance.yahoo.com'\n",
    "    r = requests.get(url)\n",
    "    \n",
    "    if r.ok:\n",
    "        time.sleep(.25)\n",
    "        data = r.json()\n",
    "        \n",
    "        payload = data[\"timeseries\"][\"result\"]\n",
    "        index_list = []\n",
    "        metric_list = []\n",
    "        count = 0\n",
    "\n",
    "        for d in range(0, len(payload)):\n",
    "            metric = payload[d][\"meta\"][\"type\"][0] \n",
    "            metric_list.append(metric) \n",
    "            index_list.append(count)\n",
    "            count += 1\n",
    "            \n",
    "#         print(f\"{index_list} : {metric_list}\")\n",
    "        comp_fin_df = pd.DataFrame({\"metric\": metric_list},\n",
    "                          index=index_list)\n",
    "        \n",
    "\n",
    "        print(f\"trying url: {url}\")\n",
    "        try: \n",
    "            for n in range(0, len(payload[fn_get_fin_metric_index(comp_fin_df, \"trailingMarketCap\")][\"trailingMarketCap\"])):\n",
    "                symbol_list.append(row.symbol)\n",
    "\n",
    "\n",
    "                # get the market cap index using the fn_get_fin_metric_index function\n",
    "                market_cap = payload[fn_get_fin_metric_index(comp_fin_df, \"trailingMarketCap\")][\"trailingMarketCap\"]\n",
    "\n",
    "                unix_timestamp_list.append(payload[fn_get_fin_metric_index(comp_fin_df, \"trailingMarketCap\")][\"timestamp\"][n])\n",
    "                date_list.append(market_cap[n][\"asOfDate\"])\n",
    "                market_cap_list.append(market_cap[n][\"reportedValue\"][\"raw\"])\n",
    "                market_cap_fmt_list.append(market_cap[n][\"reportedValue\"][\"fmt\"])\n",
    "        except KeyError:\n",
    "            continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-13T16:14:08.328745Z",
     "start_time": "2021-01-13T16:14:08.315772Z"
    }
   },
   "outputs": [],
   "source": [
    "#transform into dataframe\n",
    "market_cap_df = pd.DataFrame({\"symbol\": symbol_list,\n",
    "                                   \"unix_timestamp\": unix_timestamp_list,\n",
    "                                   \"date\": date_list,\n",
    "                                   \"market_cap\": market_cap_list,\n",
    "                                   \"market_cap_formatted\": market_cap_fmt_list, \n",
    "                                   \"date_pulled\": today\n",
    "                                  })\n",
    "\n",
    "market_cap_df[\"market_cap\"] = market_cap_df[\"market_cap\"].astype('int64')\n",
    "market_cap_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-13T15:47:29.811797Z",
     "start_time": "2021-01-13T15:47:29.646061Z"
    }
   },
   "outputs": [],
   "source": [
    "# add company info to database\n",
    "connection = engine.connect()\n",
    "market_cap_df.to_sql('market_cap', con=engine, if_exists='append', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-28T03:39:04.809610Z",
     "start_time": "2020-12-28T03:39:04.641780Z"
    }
   },
   "outputs": [],
   "source": [
    "# get single characteristics for testing\n",
    "# symbol = \"AAPL\"\n",
    "\n",
    "# symbol_list = []\n",
    "# unix_timestamp_list = []\n",
    "# date_list = []\n",
    "# market_cap_list = []\n",
    "# market_cap_fmt_list = []\n",
    "\n",
    "\n",
    "# url = f'https://query1.finance.yahoo.com/ws/fundamentals-timeseries/v1/finance/timeseries/{symbol}?lang=en-US&region=US&symbol=AAPL&padTimeSeries=true&type=quarterlyMarketCap%2CtrailingMarketCap%2CquarterlyEnterpriseValue%2CtrailingEnterpriseValue%2CquarterlyPeRatio%2CtrailingPeRatio%2CquarterlyForwardPeRatio%2CtrailingForwardPeRatio%2CquarterlyPegRatio%2CtrailingPegRatio%2CquarterlyPsRatio%2CtrailingPsRatio%2CquarterlyPbRatio%2CtrailingPbRatio%2CquarterlyEnterprisesValueRevenueRatio%2CtrailingEnterprisesValueRevenueRatio%2CquarterlyEnterprisesValueEBITDARatio%2CtrailingEnterprisesValueEBITDARatio&merge=false&period1=1514903400&period2=1608962400&corsDomain=finance.yahoo.com'\n",
    "# r = requests.get(url)\n",
    "# data = r.json()\n",
    "\n",
    "# for n in range(0, len(payload[fn_get_fin_metric_index(comp_fin_df, \"trailingMarketCap\")][\"trailingMarketCap\"])):\n",
    "#     symbol_list.append(symbol)\n",
    "    \n",
    "    \n",
    "#     # get the market cap index using the fn_get_fin_metric_index function\n",
    "#     market_cap = payload[fn_get_fin_metric_index(comp_fin_df, \"trailingMarketCap\")][\"trailingMarketCap\"]\n",
    "    \n",
    "#     unix_timestamp_list.append(payload[fn_get_fin_metric_index(comp_fin_df, \"trailingMarketCap\")][\"timestamp\"][n])\n",
    "#     date_list.append(market_cap[n][\"asOfDate\"])\n",
    "#     period_type_list.append(market_cap[n][\"periodType\"])\n",
    "#     market_cap_list.append(market_cap[n][\"reportedValue\"][\"raw\"])\n",
    "#     market_cap_fmt_list.append(market_cap[n][\"reportedValue\"][\"fmt\"])\n",
    "    \n",
    "# comp_market_cap_df = pd.DataFrame({\"symbol\": symbol_list,\n",
    "#                                    \"unix_timestamp\": unix_timestamp_list,\n",
    "#                                    \"date\": date_list,\n",
    "#                                    \"market_cap\": market_cap_list,\n",
    "#                                    \"market_cap_formatted\": market_cap_fmt_list, \n",
    "#                                    \"date_pulled\": today\n",
    "#                                   })\n",
    "\n",
    "# comp_market_cap_df[\"market_cap\"] = comp_market_cap_df[\"market_cap\"].astype('int64')\n",
    "# comp_market_cap_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-12T00:43:57.768672Z",
     "start_time": "2020-07-12T00:43:57.755696Z"
    }
   },
   "source": [
    "Information that may be interesting to share.  Examples include:\n",
    "1. Timing of when it launches, how long its been, etc.\n",
    "2. Price performance\n",
    "    - Launch date open and close price (how they did on first day)\n",
    "    - How did it do when its hit 1 month, 3 month, 6 month, 1 year milestone\n",
    "3. Industry perormance\n",
    "    - Did it outperform the S&P \n",
    "    - Did it outperform they sector (Ex: tech, consumer goods)\n",
    "4. Top performers\n",
    "    - Which IPOs did best in last 1 month, 3 month, 6 month, 1 year milestone"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-03T02:33:46.561695Z",
     "start_time": "2020-12-03T02:33:41.373Z"
    }
   },
   "outputs": [],
   "source": [
    "# Print text for each record\n",
    "\n",
    "for i in range(0,len(response)):\n",
    "  print(f\"{response[i]['expected_to_trade']}: {response[i]['company']} [{response[i]['symbol_proposed']}]. Price (Low-High): ${response[i]['price_low']}-{response[i]['price_high']}. #new_ipo_{response[i]['symbol_proposed']}\")  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-03T02:33:46.562693Z",
     "start_time": "2020-12-03T02:33:41.376Z"
    }
   },
   "outputs": [],
   "source": [
    "# Establish Twitter connection\n",
    "\n",
    "import tweepy\n",
    "\n",
    "CONSUMER_KEY = \"consumer_key\"\n",
    "CONSUMER_SECRET = \"consumer_secret\"   \n",
    "ACCESS_KEY = \"access_key\"    \n",
    "ACCESS_SECRET = \"access_secret\"\n",
    "\n",
    "auth = tweepy.OAuthHandler(CONSUMER_KEY, CONSUMER_SECRET)\n",
    "auth.set_access_token(ACCESS_KEY, ACCESS_SECRET)\n",
    "\n",
    "api = tweepy.API(auth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-03T02:33:46.563692Z",
     "start_time": "2020-12-03T02:33:41.380Z"
    }
   },
   "outputs": [],
   "source": [
    "# Post a tweet for each record\n",
    "for i in range(0,len(response)):\n",
    "  new_tweet = f\"{response[i]['expected_to_trade']}: {response[i]['company']} [{response[i]['symbol_proposed']}]. Price (Low-High): ${response[i]['price_low']}-{response[i]['price_high']}. #new_ipo_{response[i]['symbol_proposed']}\" \n",
    "  api.update_status(new_tweet)      "
   ]
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "232.188px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
